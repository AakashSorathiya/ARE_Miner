{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aakash.sorathiya\\Desktop\\research_work\\pyenv\\Lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\aakash.sorathiya\\Desktop\\research_work\\pyenv\\Lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchtext.vocab import GloVe\n",
    "import torchcrf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import ast\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2062 entries, 0 to 2061\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               2062 non-null   int64 \n",
      " 1   App id                   2062 non-null   object\n",
      " 2   Review id                2062 non-null   object\n",
      " 3   Sentence id              2062 non-null   int64 \n",
      " 4   Sentence content         2062 non-null   object\n",
      " 5   Feature (Positive)       291 non-null    object\n",
      " 6   Feature (Neutral)        638 non-null    object\n",
      " 7   Feature (Negative)       110 non-null    object\n",
      " 8   Feature (All Annotated)  971 non-null    object\n",
      " 9   clean_content            2062 non-null   object\n",
      " 10  tags                     2062 non-null   object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 177.3+ KB\n"
     ]
    }
   ],
   "source": [
    "truth_dataset = pd.read_csv('../datafiles/true_tags.csv')\n",
    "truth_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_dataset['clean_content'] = truth_dataset['clean_content'].apply(ast.literal_eval)\n",
    "truth_dataset['tags'] = truth_dataset['tags'].apply(ast.literal_eval)\n",
    "truth_dataset = truth_dataset[truth_dataset['clean_content'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "App id\n",
       "B004LOMB2Q                    367\n",
       "B005ZXWMUS                    341\n",
       "B0094BB4TW                    327\n",
       "B004SIIBGU                    294\n",
       "com.spotify.music             226\n",
       "com.twitter.android           183\n",
       "com.whatsapp                  169\n",
       "com.zentertain.photoeditor    154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_dataset['App id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(truth_dataset[truth_dataset['App id']=='B004LOMB2Q']['clean_content'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2061\n",
      "2061\n"
     ]
    }
   ],
   "source": [
    "all_sentences = truth_dataset['clean_content'].to_list()\n",
    "all_tags = truth_dataset['tags'].to_list()\n",
    "\n",
    "print(len(all_sentences))\n",
    "print(len(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {word: i+1 for i, word in enumerate(set([w for s in all_sentences for w in s]))}\n",
    "word_to_ix['<PAD>']=0\n",
    "word_to_ix['<UNK>']=len(word_to_ix)\n",
    "tag_to_ix = {'<PAD>': 0, 'B': 1, 'I': 2, 'O': 3}\n",
    "ix_to_tag = {ix: tag for tag, ix in tag_to_ix.items()}\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(sentences, tags, word_to_ix, tag_to_ix, pad_idx=0):\n",
    "    max_len = max(len(s) for s in sentences)\n",
    "    \n",
    "    sentences_idx = [[word_to_ix[word] for word in sent] + [pad_idx] * (max_len - len(sent)) for sent in sentences]\n",
    "    tags_idx = [[tag_to_ix[tag] for tag in tag_seq] + [pad_idx] * (max_len - len(tag_seq)) for tag_seq in tags]\n",
    "    \n",
    "    sentences_tensor = torch.tensor(sentences_idx, dtype=torch.long)\n",
    "    tags_tensor = torch.tensor(tags_idx, dtype=torch.long)\n",
    "    \n",
    "    return TensorDataset(sentences_tensor, tags_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences, test_sentences, dev_tags, test_tags = train_test_split(all_sentences, all_tags, test_size=0.2, random_state=42)\n",
    "train_sentences, val_sentences, train_tags, val_tags = train_test_split(dev_sentences, dev_tags, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = prepare_data(train_sentences, train_tags, word_to_ix, tag_to_ix)\n",
    "val_data = prepare_data(val_sentences, val_tags, word_to_ix, tag_to_ix)\n",
    "test_data = prepare_data(test_sentences, test_tags, word_to_ix, tag_to_ix)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B004LOMB2Q\n",
      "1694 367\n",
      "B005ZXWMUS\n",
      "1720 341\n",
      "B0094BB4TW\n",
      "1734 327\n",
      "B004SIIBGU\n",
      "1767 294\n",
      "com.spotify.music\n",
      "1835 226\n",
      "com.twitter.android\n",
      "1878 183\n",
      "com.whatsapp\n",
      "1892 169\n",
      "com.zentertain.photoeditor\n",
      "1907 154\n"
     ]
    }
   ],
   "source": [
    "cross_domain_data = []\n",
    "for app in truth_dataset['App id'].value_counts().keys():\n",
    "    print(app)\n",
    "    dev_sentences = truth_dataset[truth_dataset['App id']!=app]['clean_content'].to_list()\n",
    "    dev_tags = truth_dataset[truth_dataset['App id']!=app]['tags'].to_list()\n",
    "    test_sentences = truth_dataset[truth_dataset['App id']==app]['clean_content'].to_list()\n",
    "    test_tags = truth_dataset[truth_dataset['App id']==app]['tags'].to_list()\n",
    "\n",
    "    print(len(dev_sentences), len(test_sentences))\n",
    "\n",
    "    train_sentences, val_sentences, train_tags, val_tags = train_test_split(dev_sentences, dev_tags, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_data = prepare_data(train_sentences, train_tags, word_to_ix, tag_to_ix)\n",
    "    val_data = prepare_data(val_sentences, val_tags, word_to_ix, tag_to_ix)\n",
    "    test_data = prepare_data(test_sentences, test_tags, word_to_ix, tag_to_ix)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    cross_domain_data.append({'app': app, 'train_loader': train_loader, 'val_loader': val_loader, 'test_loader': test_loader, 'test_sentences': test_sentences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, glove_embeddings):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_embeddings, freeze=False)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True, batch_first=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embedding(inputs)\n",
    "        out, hidden = self.encoder(embeds)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, tagset_size) -> None:\n",
    "        super().__init__()\n",
    "        self.decoder = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "    \n",
    "    def forward(self, decoder_inputs):\n",
    "        out, hidden = self.decoder(decoder_inputs)\n",
    "        emissions = self.fc(out)\n",
    "        return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        attention_weights = torch.tanh(self.attention(input))\n",
    "        attention_weights = torch.softmax(attention_weights, dim=1)\n",
    "        out = input * attention_weights\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, tagset_size, encoder, decoder, attention):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.attention = attention\n",
    "        self.crf = torchcrf.CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        out, _ = self.encoder(sentence)\n",
    "        out = self.attention(out)\n",
    "        emissions = self.decoder(out)\n",
    "        \n",
    "        return emissions\n",
    "    \n",
    "    def loss(self, emissions, tags, mask=None):\n",
    "        return -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "    \n",
    "    def decode(self, emissions, mask=None):\n",
    "        return self.crf.decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 512\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "TAGSET_SIZE = len(tag_to_ix)\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = GloVe(name='6B', dim=EMBEDDING_DIM)\n",
    "\n",
    "glove_embeddings = torch.zeros(VOCAB_SIZE, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2818, 300])\n"
     ]
    }
   ],
   "source": [
    "for word, idx in word_to_ix.items():\n",
    "    if word in glove.stoi:\n",
    "        glove_embeddings[idx] = glove[word]\n",
    "    else:\n",
    "        glove_embeddings[idx] = torch.randn(EMBEDDING_DIM)\n",
    "\n",
    "print(glove_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = BiLSTMEncoder(EMBEDDING_DIM, HIDDEN_DIM, glove_embeddings)\n",
    "decoder = LSTMDecoder(HIDDEN_DIM, TAGSET_SIZE)\n",
    "attention = SelfAttention(HIDDEN_DIM)\n",
    "model = Seq2SeqModel(TAGSET_SIZE, encoder, decoder, attention)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for sentences_batch, tags_batch in train_loader:\n",
    "        mask = (sentences_batch != 0)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        emissions = model(sentences_batch)\n",
    "\n",
    "        loss = model.loss(emissions, tags_batch, mask)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Train Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for sentences_batch, tags_batch in val_loader:\n",
    "            mask = (sentences_batch != 0)\n",
    "            emissions = model(sentences_batch)\n",
    "            loss = model.loss(emissions, tags_batch, mask)\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Validation Loss: {total_loss / len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_loop(model, train_loader, val_loader, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch: {epoch}')\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase=='train':\n",
    "                train_model(model, train_loader, optimizer)\n",
    "            else:\n",
    "                evaluate_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss: 8.235164937518892\n",
      "Validation Loss: 4.840473370118574\n",
      "Epoch: 1\n",
      "Train Loss: 3.823301831881205\n",
      "Validation Loss: 4.1454877419905225\n",
      "Epoch: 2\n",
      "Train Loss: 2.4943369783106304\n",
      "Validation Loss: 3.948097337375988\n",
      "Epoch: 3\n",
      "Train Loss: 2.048884467000053\n",
      "Validation Loss: 4.039437185634267\n",
      "Epoch: 4\n",
      "Train Loss: 1.6912370856319154\n",
      "Validation Loss: 4.471763329072432\n",
      "Epoch: 5\n",
      "Train Loss: 1.3907384088351613\n",
      "Validation Loss: 4.363630013032393\n",
      "Epoch: 6\n",
      "Train Loss: 1.1941032116966588\n",
      "Validation Loss: 4.195348609577525\n",
      "Epoch: 7\n",
      "Train Loss: 1.112944009935572\n",
      "Validation Loss: 4.361788099462336\n",
      "Epoch: 8\n",
      "Train Loss: 0.9677009975005474\n",
      "Validation Loss: 5.029920512979681\n",
      "Epoch: 9\n",
      "Train Loss: 0.8925407479206721\n",
      "Validation Loss: 4.3115399859168315\n",
      "Epoch: 10\n",
      "Train Loss: 0.7250430214972723\n",
      "Validation Loss: 4.797048449516296\n",
      "Epoch: 11\n",
      "Train Loss: 0.6777466975507282\n",
      "Validation Loss: 4.943498860705983\n",
      "Epoch: 12\n",
      "Train Loss: 0.5961136810836338\n",
      "Validation Loss: 5.108651811426336\n",
      "Epoch: 13\n",
      "Train Loss: 0.5087492334700766\n",
      "Validation Loss: 6.103776628320867\n",
      "Epoch: 14\n",
      "Train Loss: 0.5339649177732921\n",
      "Validation Loss: 5.616518237374046\n",
      "Epoch: 15\n",
      "Train Loss: 0.6472502453696161\n",
      "Validation Loss: 4.635108839381825\n",
      "Epoch: 16\n",
      "Train Loss: 0.4468946769123986\n",
      "Validation Loss: 5.459038160064003\n",
      "Epoch: 17\n",
      "Train Loss: 0.5178304659646182\n",
      "Validation Loss: 4.974197940392927\n",
      "Epoch: 18\n",
      "Train Loss: 0.39706123602532206\n",
      "Validation Loss: 5.709635387767445\n",
      "Epoch: 19\n",
      "Train Loss: 0.3113380954379127\n",
      "Validation Loss: 6.249231425198642\n",
      "Epoch: 20\n",
      "Train Loss: 0.2935156651905605\n",
      "Validation Loss: 6.645108526403254\n",
      "Epoch: 21\n",
      "Train Loss: 0.3529135934298947\n",
      "Validation Loss: 6.19860425862399\n",
      "Epoch: 22\n",
      "Train Loss: 0.3122686293153536\n",
      "Validation Loss: 6.076972874728116\n",
      "Epoch: 23\n",
      "Train Loss: 0.24446814595943406\n",
      "Validation Loss: 6.886328307065097\n",
      "Epoch: 24\n",
      "Train Loss: 0.2989325200517972\n",
      "Validation Loss: 6.355651205236262\n"
     ]
    }
   ],
   "source": [
    "train_eval_loop(model, train_loader, val_loader, optimizer, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    masks = []\n",
    "    with torch.no_grad():\n",
    "        for sentences_batch, _ in test_loader:\n",
    "            mask = (sentences_batch != 0)\n",
    "            emissions = model(sentences_batch)\n",
    "            predictions = model.decode(emissions, mask=mask)\n",
    "            pred_tags = [[ix_to_tag[t] for t in seq] for seq in predictions]\n",
    "            \n",
    "            all_predictions.extend(pred_tags)\n",
    "            masks.extend(mask)\n",
    "    \n",
    "    return all_predictions, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions, masks = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_exact_match(true_tags, pred_tags, tag_to_ix, masks):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for true_seq, pred_seq, mask_seq in zip(true_tags, pred_tags, masks):\n",
    "        # print(len(true_seq), len(pred_seq))\n",
    "        for i, m in enumerate(mask_seq):\n",
    "            if m:\n",
    "                y_true.append(true_seq[i])\n",
    "                y_pred.append(pred_seq[i])\n",
    "    \n",
    "    # y_true = [tag_to_ix[tag] for tag in y_true]\n",
    "    # y_pred = [tag_to_ix[tag] for tag in y_pred]\n",
    "    \n",
    "    print(set(y_true), set(y_pred))\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O', 'B', 'I'} {'O', 'B', 'I'}\n",
      "Exact Match - Precision: 0.7142572950373802, Recall: 0.706020111884896, F1: 0.7091976436876989\n"
     ]
    }
   ],
   "source": [
    "exact_precision, exact_recall, exact_f1 = test_exact_match(test_tags, test_predictions, tag_to_ix, masks)\n",
    "print(f\"Exact Match - Precision: {exact_precision}, Recall: {exact_recall}, F1: {exact_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_1(predictions, true_tags, true_tokens):\n",
    "    \n",
    "    # print(len(predictions), len(true_tags), len(test_sentences))\n",
    "    levels = 3\n",
    "    \n",
    "    def extract_entities(seq, sentence):\n",
    "\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        \n",
    "        for i, tag in enumerate(seq):\n",
    "            if tag == 'B':\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                current_entity = [sentence[i]]\n",
    "            elif tag == 'I':\n",
    "                if current_entity is None:\n",
    "                    current_entity = [sentence[i]]\n",
    "                else:\n",
    "                    current_entity.append(sentence[i])\n",
    "            elif tag == 'O':\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "        \n",
    "        if current_entity:\n",
    "            entities.append(current_entity)\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    def is_match(f1, f2, n):\n",
    "        \"\"\"\n",
    "        Check if two features match at level n.\n",
    "        Conditions:\n",
    "        1. One feature is equal to or is a subset of the other\n",
    "        2. Absolute length difference is at most n\n",
    "        \"\"\"\n",
    "        f1=set(f1)\n",
    "        f2=set(f2)\n",
    "        \n",
    "        is_subset = f1.issubset(f2) or f2.issubset(f1)\n",
    "        length_diff = abs(len(f1) - len(f2))\n",
    "        \n",
    "        return is_subset and length_diff <= n\n",
    "\n",
    "\n",
    "    all_true_entites = []\n",
    "    all_pred_entites = []\n",
    "    \n",
    "    for pred_seq, true_seq, token_seq in zip(predictions, true_tags, true_tokens):\n",
    "        true_entities = extract_entities(true_seq, token_seq)\n",
    "        pred_entities = extract_entities(pred_seq, token_seq)\n",
    "        # print(pred_entities)\n",
    "        # print(true_entities)\n",
    "\n",
    "        all_true_entites.append(true_entities)\n",
    "        all_pred_entites.append(pred_entities)\n",
    "\n",
    "    total_true = len(all_true_entites)\n",
    "    total_pred = len(all_pred_entites)\n",
    "    metrics = {}\n",
    "    # print(total_pred, total_true, all_levels_TPs)\n",
    "\n",
    "    for level in range(levels):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        for true_entities, pred_entities in zip(all_true_entites, all_pred_entites):   \n",
    "            matched_true = set()\n",
    "            for pred_entity in pred_entities:\n",
    "                found_match = False\n",
    "                \n",
    "                for i, true_entity in enumerate(true_entities):\n",
    "                    if i not in matched_true and is_match(pred_entity, true_entity, level):\n",
    "                        tp += 1\n",
    "                        matched_true.add(i)\n",
    "                        found_match = True\n",
    "                        break\n",
    "                \n",
    "                if not found_match:\n",
    "                    fp += 1\n",
    "\n",
    "            fn += len(true_entities) - len(matched_true)\n",
    "            # print(fn)\n",
    "    \n",
    "        print(level, tp, fp, fn)\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        level_name = ['exact', 'n-1', 'n-2'][level]\n",
    "        metrics.update({\n",
    "            f'{level_name}_precision': precision,\n",
    "            f'{level_name}_recall': recall,\n",
    "            f'{level_name}_f1': f1\n",
    "        })\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_2(predictions, true_tags):\n",
    "    \n",
    "    def extract_entities(seq):\n",
    "\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        \n",
    "        for i, tag in enumerate(seq):\n",
    "            if tag == 'B':\n",
    "                if current_entity:\n",
    "                    entities.append((current_entity[0], i-1))\n",
    "                current_entity = (i,)\n",
    "            elif tag == 'I':\n",
    "                if current_entity is None:\n",
    "                    current_entity = (i,)\n",
    "            elif tag == 'O':\n",
    "                if current_entity:\n",
    "                    entities.append((current_entity[0], i-1))\n",
    "                    current_entity = None\n",
    "        \n",
    "        if current_entity:\n",
    "            entities.append((current_entity[0], len(seq)-1))\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for pred_seq, true_seq in zip(predictions, true_tags):\n",
    "        pred_entities = set(extract_entities(pred_seq))\n",
    "        true_entities = set(extract_entities(true_seq))\n",
    "        \n",
    "        true_positives += len(pred_entities & true_entities)\n",
    "        false_positives += len(pred_entities - true_entities)\n",
    "        false_negatives += len(true_entities - pred_entities)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 127 175 153\n",
      "1 161 141 119\n",
      "2 180 122 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_precision': 0.4205298013245033,\n",
       " 'exact_recall': 0.45357142857142857,\n",
       " 'exact_f1': 0.436426116838488,\n",
       " 'n-1_precision': 0.5331125827814569,\n",
       " 'n-1_recall': 0.575,\n",
       " 'n-1_f1': 0.5532646048109965,\n",
       " 'n-2_precision': 0.5960264900662252,\n",
       " 'n-2_recall': 0.6428571428571429,\n",
       " 'n-2_f1': 0.6185567010309279}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics_1(test_predictions, test_tags, test_sentences)\n",
    "# calculate_metrics_2(test_predictions, test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model_across_domains(epochs):\n",
    "    results=[]\n",
    "    \n",
    "    for data in cross_domain_data:\n",
    "        print(f'For app: {data['app']}')\n",
    "        model = Seq2SeqModel(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAGSET_SIZE, glove_embeddings)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        train_eval_loop(model, data['train_loader'], data['val_loader'], optimizer, epochs)\n",
    "        test_predictions, masks = test_model(model, test_loader)\n",
    "        f1_scores = calculate_metrics_1(test_predictions, test_tags, test_sentences)\n",
    "        results.append({data['app']: f1_scores})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For app: com.zentertain.photoeditor\n",
      "Epoch: 0\n",
      "Train Loss: 7.805342613264572\n",
      "Validation Loss: 5.477112770080566\n",
      "Epoch: 1\n",
      "Train Loss: 4.253778269124585\n",
      "Validation Loss: 3.832847161726518\n",
      "Epoch: 2\n",
      "Train Loss: 3.0995182658350746\n",
      "Validation Loss: 3.445531715046276\n",
      "Epoch: 3\n",
      "Train Loss: 2.4657742616742158\n",
      "Validation Loss: 3.3044710592790083\n",
      "Epoch: 4\n",
      "Train Loss: 2.040808748367221\n",
      "Validation Loss: 3.3759177164597944\n",
      "Epoch: 5\n",
      "Train Loss: 1.7147681519042615\n",
      "Validation Loss: 3.5015265074643223\n",
      "Epoch: 6\n",
      "Train Loss: 1.3128584664921428\n",
      "Validation Loss: 3.7212621081959116\n",
      "Epoch: 7\n",
      "Train Loss: 1.1011630206607108\n",
      "Validation Loss: 3.85394607890736\n",
      "Epoch: 8\n",
      "Train Loss: 0.9755697153335394\n",
      "Validation Loss: 3.9998093084855513\n",
      "Epoch: 9\n",
      "Train Loss: 0.7582010599069817\n",
      "Validation Loss: 4.10980393669822\n",
      "0 74 14 17\n",
      "1 80 8 11\n",
      "2 83 5 8\n",
      "For app: com.zentertain.photoeditor\n",
      "Epoch: 0\n",
      "Train Loss: 8.06432899208956\n",
      "Validation Loss: 5.992537325078791\n",
      "Epoch: 1\n",
      "Train Loss: 3.9946117927861766\n",
      "Validation Loss: 4.281915664672852\n",
      "Epoch: 2\n",
      "Train Loss: 2.5471632757852243\n",
      "Validation Loss: 4.329253673553467\n",
      "Epoch: 3\n",
      "Train Loss: 1.9652542846147405\n",
      "Validation Loss: 4.0720414031635634\n",
      "Epoch: 4\n",
      "Train Loss: 1.5310440673384555\n",
      "Validation Loss: 4.905728166753596\n",
      "Epoch: 5\n",
      "Train Loss: 1.2872825916423354\n",
      "Validation Loss: 4.581979881633412\n",
      "Epoch: 6\n",
      "Train Loss: 1.146696396345316\n",
      "Validation Loss: 5.2262984622608535\n",
      "Epoch: 7\n",
      "Train Loss: 0.9616253999776618\n",
      "Validation Loss: 4.565589048645713\n",
      "Epoch: 8\n",
      "Train Loss: 0.8618466278841329\n",
      "Validation Loss: 5.257422555576671\n",
      "Epoch: 9\n",
      "Train Loss: 0.7117988612762717\n",
      "Validation Loss: 5.005709539760243\n",
      "0 74 10 17\n",
      "1 80 4 11\n",
      "2 81 3 10\n",
      "For app: com.zentertain.photoeditor\n",
      "Epoch: 0\n",
      "Train Loss: 8.432677496563304\n",
      "Validation Loss: 4.771979938853871\n",
      "Epoch: 1\n",
      "Train Loss: 3.5281540047038686\n",
      "Validation Loss: 3.9777820110321045\n",
      "Epoch: 2\n",
      "Train Loss: 2.1543793976306915\n",
      "Validation Loss: 3.69007455218922\n",
      "Epoch: 3\n",
      "Train Loss: 1.5278309380466288\n",
      "Validation Loss: 3.6861049695448442\n",
      "Epoch: 4\n",
      "Train Loss: 1.1996332176707007\n",
      "Validation Loss: 4.115158622915095\n",
      "Epoch: 5\n",
      "Train Loss: 0.9942418932914734\n",
      "Validation Loss: 4.641714963045987\n",
      "Epoch: 6\n",
      "Train Loss: 0.9008939801291986\n",
      "Validation Loss: 4.417989427393133\n",
      "Epoch: 7\n",
      "Train Loss: 0.7812981930646029\n",
      "Validation Loss: 4.961856354366649\n",
      "Epoch: 8\n",
      "Train Loss: 0.7445026710629463\n",
      "Validation Loss: 5.0968077833002265\n",
      "Epoch: 9\n",
      "Train Loss: 0.6657139672474428\n",
      "Validation Loss: 5.215565323829651\n",
      "0 76 13 15\n",
      "1 80 9 11\n",
      "2 83 6 8\n",
      "For app: com.zentertain.photoeditor\n",
      "Epoch: 0\n",
      "Train Loss: 7.792235798305935\n",
      "Validation Loss: 5.579571962356567\n",
      "Epoch: 1\n",
      "Train Loss: 3.1865128490659926\n",
      "Validation Loss: 4.212872405846913\n",
      "Epoch: 2\n",
      "Train Loss: 1.9551206363572016\n",
      "Validation Loss: 3.676718443632126\n",
      "Epoch: 3\n",
      "Train Loss: 1.5252421001593273\n",
      "Validation Loss: 3.292086601257324\n",
      "Epoch: 4\n",
      "Train Loss: 1.2336944805251226\n",
      "Validation Loss: 3.600584924221039\n",
      "Epoch: 5\n",
      "Train Loss: 0.9733984557808273\n",
      "Validation Loss: 3.2865957220395408\n",
      "Epoch: 6\n",
      "Train Loss: 0.8587040980656941\n",
      "Validation Loss: 4.3461790680885315\n",
      "Epoch: 7\n",
      "Train Loss: 0.780069457160102\n",
      "Validation Loss: 3.546166976292928\n",
      "Epoch: 8\n",
      "Train Loss: 0.7836847828494178\n",
      "Validation Loss: 3.613959630330404\n",
      "Epoch: 9\n",
      "Train Loss: 0.7599347260263231\n",
      "Validation Loss: 3.2929225961367288\n",
      "0 79 13 12\n",
      "1 82 10 9\n",
      "2 84 8 7\n",
      "For app: com.zentertain.photoeditor\n",
      "Epoch: 0\n",
      "Train Loss: 7.316094657649165\n",
      "Validation Loss: 4.40958559513092\n",
      "Epoch: 1\n",
      "Train Loss: 3.0077400129774343\n",
      "Validation Loss: 3.0687758922576904\n",
      "Epoch: 2\n",
      "Train Loss: 1.820597300063009\n",
      "Validation Loss: 2.846446787317594\n",
      "Epoch: 3\n",
      "Train Loss: 1.2499345346637394\n",
      "Validation Loss: 3.1117273370424905\n",
      "Epoch: 4\n",
      "Train Loss: 1.0738425047501274\n",
      "Validation Loss: 3.376669784386953\n",
      "Epoch: 5\n",
      "Train Loss: 0.8746116005856058\n",
      "Validation Loss: 3.7405691047509513\n",
      "Epoch: 6\n",
      "Train Loss: 0.7515730786582698\n",
      "Validation Loss: 3.735708256562551\n",
      "Epoch: 7\n",
      "Train Loss: 0.6714262223762014\n",
      "Validation Loss: 3.9960073630015054\n",
      "Epoch: 8\n",
      "Train Loss: 0.5764551875383958\n",
      "Validation Loss: 4.251180311044057\n",
      "Epoch: 9\n",
      "Train Loss: 0.5411117543344912\n",
      "Validation Loss: 4.59786398212115\n",
      "0 78 13 13\n",
      "1 85 6 6\n",
      "2 87 4 4\n",
      "For app: com.zentertain.photoeditor\n",
      "Epoch: 0\n",
      "Train Loss: 8.449991048650539\n",
      "Validation Loss: 5.020944535732269\n",
      "Epoch: 1\n",
      "Train Loss: 3.2630861185966653\n",
      "Validation Loss: 3.987439304590225\n",
      "Epoch: 2\n",
      "Train Loss: 1.7020367231774838\n",
      "Validation Loss: 2.29142893354098\n",
      "Epoch: 3\n",
      "Train Loss: 1.2150627666331353\n",
      "Validation Loss: 2.7145624409119287\n",
      "Epoch: 4\n",
      "Train Loss: 1.0372591424495616\n",
      "Validation Loss: 2.4576249172290168\n",
      "Epoch: 5\n",
      "Train Loss: 0.803772435543385\n",
      "Validation Loss: 2.845439846316973\n",
      "Epoch: 6\n",
      "Train Loss: 0.7236067218349335\n",
      "Validation Loss: 2.870365172624588\n",
      "Epoch: 7\n",
      "Train Loss: 0.6141744782315924\n",
      "Validation Loss: 3.2037740349769592\n",
      "Epoch: 8\n",
      "Train Loss: 0.5257701797688261\n",
      "Validation Loss: 3.107608507076899\n",
      "Epoch: 9\n",
      "Train Loss: 0.5230603053214702\n",
      "Validation Loss: 3.259295811255773\n",
      "0 81 11 10\n",
      "1 84 8 7\n",
      "2 87 5 4\n",
      "For app: com.zentertain.photoeditor\n",
      "Epoch: 0\n",
      "Train Loss: 8.385779390732447\n",
      "Validation Loss: 4.731478691101074\n",
      "Epoch: 1\n",
      "Train Loss: 3.183660678565502\n",
      "Validation Loss: 2.5439486652612686\n",
      "Epoch: 2\n",
      "Train Loss: 1.7833331724007924\n",
      "Validation Loss: 2.379421219229698\n",
      "Epoch: 3\n",
      "Train Loss: 1.1995784292618434\n",
      "Validation Loss: 2.4112207194169364\n",
      "Epoch: 4\n",
      "Train Loss: 0.9167138654738665\n",
      "Validation Loss: 2.9529352386792502\n",
      "Epoch: 5\n",
      "Train Loss: 0.7791604970892271\n",
      "Validation Loss: 2.7019756585359573\n",
      "Epoch: 6\n",
      "Train Loss: 0.73384461303552\n",
      "Validation Loss: 2.9673897276322045\n",
      "Epoch: 7\n",
      "Train Loss: 0.6329981226784488\n",
      "Validation Loss: 2.956740379333496\n",
      "Epoch: 8\n",
      "Train Loss: 0.6012989260489121\n",
      "Validation Loss: 2.880575031042099\n",
      "Epoch: 9\n",
      "Train Loss: 0.4721113170186679\n",
      "Validation Loss: 4.045200765132904\n",
      "0 73 13 18\n",
      "1 81 5 10\n",
      "2 84 2 7\n",
      "For app: com.zentertain.photoeditor\n",
      "Epoch: 0\n",
      "Train Loss: 7.593181932965915\n",
      "Validation Loss: 3.827794849872589\n",
      "Epoch: 1\n",
      "Train Loss: 2.767670369396607\n",
      "Validation Loss: 2.0648776094118753\n",
      "Epoch: 2\n",
      "Train Loss: 1.5964757539331913\n",
      "Validation Loss: 1.8224282761414845\n",
      "Epoch: 3\n",
      "Train Loss: 1.242522685478131\n",
      "Validation Loss: 1.5476140479246776\n",
      "Epoch: 4\n",
      "Train Loss: 0.9642398661623398\n",
      "Validation Loss: 3.2362741231918335\n",
      "Epoch: 5\n",
      "Train Loss: 0.8489610546578964\n",
      "Validation Loss: 2.2080520540475845\n",
      "Epoch: 6\n",
      "Train Loss: 0.7558015768105785\n",
      "Validation Loss: 2.2401814063390098\n",
      "Epoch: 7\n",
      "Train Loss: 0.6237687158087889\n",
      "Validation Loss: 1.860751340786616\n",
      "Epoch: 8\n",
      "Train Loss: 0.5929601094685495\n",
      "Validation Loss: 2.356426934401194\n",
      "Epoch: 9\n",
      "Train Loss: 0.49640441220253706\n",
      "Validation Loss: 2.3282739222049713\n",
      "0 65 24 26\n",
      "1 73 16 18\n",
      "2 79 10 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'B004LOMB2Q': {'exact_precision': 0.8409090909090909,\n",
       "   'exact_recall': 0.8131868131868132,\n",
       "   'exact_f1': 0.8268156424581005,\n",
       "   'n-1_precision': 0.9090909090909091,\n",
       "   'n-1_recall': 0.8791208791208791,\n",
       "   'n-1_f1': 0.8938547486033518,\n",
       "   'n-2_precision': 0.9431818181818182,\n",
       "   'n-2_recall': 0.9120879120879121,\n",
       "   'n-2_f1': 0.9273743016759776}},\n",
       " {'B005ZXWMUS': {'exact_precision': 0.8809523809523809,\n",
       "   'exact_recall': 0.8131868131868132,\n",
       "   'exact_f1': 0.8457142857142858,\n",
       "   'n-1_precision': 0.9523809523809523,\n",
       "   'n-1_recall': 0.8791208791208791,\n",
       "   'n-1_f1': 0.9142857142857143,\n",
       "   'n-2_precision': 0.9642857142857143,\n",
       "   'n-2_recall': 0.8901098901098901,\n",
       "   'n-2_f1': 0.9257142857142856}},\n",
       " {'B0094BB4TW': {'exact_precision': 0.8539325842696629,\n",
       "   'exact_recall': 0.8351648351648352,\n",
       "   'exact_f1': 0.8444444444444446,\n",
       "   'n-1_precision': 0.898876404494382,\n",
       "   'n-1_recall': 0.8791208791208791,\n",
       "   'n-1_f1': 0.8888888888888888,\n",
       "   'n-2_precision': 0.9325842696629213,\n",
       "   'n-2_recall': 0.9120879120879121,\n",
       "   'n-2_f1': 0.9222222222222223}},\n",
       " {'B004SIIBGU': {'exact_precision': 0.8586956521739131,\n",
       "   'exact_recall': 0.8681318681318682,\n",
       "   'exact_f1': 0.8633879781420766,\n",
       "   'n-1_precision': 0.8913043478260869,\n",
       "   'n-1_recall': 0.9010989010989011,\n",
       "   'n-1_f1': 0.8961748633879782,\n",
       "   'n-2_precision': 0.9130434782608695,\n",
       "   'n-2_recall': 0.9230769230769231,\n",
       "   'n-2_f1': 0.9180327868852459}},\n",
       " {'com.spotify.music': {'exact_precision': 0.8571428571428571,\n",
       "   'exact_recall': 0.8571428571428571,\n",
       "   'exact_f1': 0.8571428571428571,\n",
       "   'n-1_precision': 0.9340659340659341,\n",
       "   'n-1_recall': 0.9340659340659341,\n",
       "   'n-1_f1': 0.9340659340659341,\n",
       "   'n-2_precision': 0.9560439560439561,\n",
       "   'n-2_recall': 0.9560439560439561,\n",
       "   'n-2_f1': 0.9560439560439561}},\n",
       " {'com.twitter.android': {'exact_precision': 0.8804347826086957,\n",
       "   'exact_recall': 0.8901098901098901,\n",
       "   'exact_f1': 0.8852459016393442,\n",
       "   'n-1_precision': 0.9130434782608695,\n",
       "   'n-1_recall': 0.9230769230769231,\n",
       "   'n-1_f1': 0.9180327868852459,\n",
       "   'n-2_precision': 0.9456521739130435,\n",
       "   'n-2_recall': 0.9560439560439561,\n",
       "   'n-2_f1': 0.9508196721311475}},\n",
       " {'com.whatsapp': {'exact_precision': 0.8488372093023255,\n",
       "   'exact_recall': 0.8021978021978022,\n",
       "   'exact_f1': 0.8248587570621468,\n",
       "   'n-1_precision': 0.9418604651162791,\n",
       "   'n-1_recall': 0.8901098901098901,\n",
       "   'n-1_f1': 0.9152542372881357,\n",
       "   'n-2_precision': 0.9767441860465116,\n",
       "   'n-2_recall': 0.9230769230769231,\n",
       "   'n-2_f1': 0.9491525423728814}},\n",
       " {'com.zentertain.photoeditor': {'exact_precision': 0.7303370786516854,\n",
       "   'exact_recall': 0.7142857142857143,\n",
       "   'exact_f1': 0.7222222222222223,\n",
       "   'n-1_precision': 0.8202247191011236,\n",
       "   'n-1_recall': 0.8021978021978022,\n",
       "   'n-1_f1': 0.8111111111111112,\n",
       "   'n-2_precision': 0.8876404494382022,\n",
       "   'n-2_recall': 0.8681318681318682,\n",
       "   'n-2_f1': 0.8777777777777778}}]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_test_model_across_domains(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B', 'I', 'O', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B']\n"
     ]
    }
   ],
   "source": [
    "inference_sentence = 'The app crashes when I try to share photos with my contacts from another social network'\n",
    "tokens = inference_sentence.split()\n",
    "sentence_idx = [word_to_ix.get(word, word_to_ix['<UNK>']) for word in tokens]\n",
    "sentence_tensor = torch.tensor([sentence_idx], dtype=torch.long)\n",
    "\n",
    "model.eval()\n",
    "emissions = model(sentence_tensor)\n",
    "pred_tags_ix = model.decode(emissions)\n",
    "pred_tags = [ix_to_tag[t] for t in pred_tags_ix[0]]\n",
    "print(pred_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
